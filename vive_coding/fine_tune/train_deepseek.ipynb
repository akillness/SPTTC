{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek 모델 파인튜닝\n",
    "\n",
    "이 노트북은 DeepSeek 모델을 파인튜닝하기 위한 코드를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.mps\n",
    "import unicodedata\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정값 정의\n",
    "DATA_DIR = os.path.abspath(\"./LiarHeart_dataset\")\n",
    "MODEL_ID = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "OUTPUT_DIR = \"./deepseek-r1-finetuned\"\n",
    "TB_LOG_DIR = os.path.join(OUTPUT_DIR, \"tensorboard_logs\")\n",
    "\n",
    "# LoRA 설정\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.1\n",
    "LORA_TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    "\n",
    "# 학습 설정\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 16\n",
    "LEARNING_RATE = 5e-4\n",
    "NUM_EPOCHS = 1\n",
    "MAX_LENGTH = 512\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "# 처리할 시트 목록\n",
    "SHEET_NAMES = [\"알리바이_대화\", \"인터뷰_대화\", \"가쉽_대화\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 및 준비 함수\n",
    "def load_and_prepare_data():\n",
    "    all_data = []\n",
    "    \n",
    "    # Excel 파일 찾기\n",
    "    search_prefix = \"페르소나 데이터_\"\n",
    "    search_suffix = \".xlsx\"\n",
    "    normalized_prefix = unicodedata.normalize('NFC', search_prefix)\n",
    "    \n",
    "    print(f\"Searching for files in {DATA_DIR}\")\n",
    "    EXCEL_FILES = []\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        normalized_filename = unicodedata.normalize('NFC', filename)\n",
    "        if normalized_filename.startswith(normalized_prefix) and normalized_filename.endswith(search_suffix) and not normalized_filename.startswith(\"~$\"):\n",
    "            EXCEL_FILES.append(os.path.join(DATA_DIR, filename))\n",
    "    print(f\"Found Excel files: {EXCEL_FILES}\")\n",
    "    \n",
    "    for excel_file in tqdm(EXCEL_FILES, desc=\"Loading Excel files\"):\n",
    "        print(f\"Processing file: {excel_file}\")\n",
    "        \n",
    "        for sheet_name in SHEET_NAMES:\n",
    "            try:\n",
    "                print(f\"  Reading sheet: {sheet_name}\")\n",
    "                df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "                \n",
    "                human_col = '사람 대사'\n",
    "                assistant_col = '챗봇 대사'\n",
    "                \n",
    "                if human_col in df.columns and assistant_col in df.columns:\n",
    "                    for _, row in df.iterrows():\n",
    "                        question = row[human_col]\n",
    "                        answer = row[assistant_col]\n",
    "                        \n",
    "                        if pd.isna(question) or pd.isna(answer):\n",
    "                            continue\n",
    "                            \n",
    "                        question = str(question)\n",
    "                        answer = str(answer)\n",
    "                        \n",
    "                        dialogue_type = \"\"\n",
    "                        if sheet_name == \"알리바이_대화\": dialogue_type = \"알리바이\"\n",
    "                        elif sheet_name == \"인터뷰_대화\": dialogue_type = \"인터뷰\"\n",
    "                        elif sheet_name == \"가쉽_대화\": dialogue_type = \"가쉽\"\n",
    "                        \n",
    "                        if dialogue_type:\n",
    "                            formatted_text = f\"<dialogue_type>\\n{dialogue_type}\\n</dialogue_type>\\n\\n<human>\\n{question}\\n</human>\\n\\n<assistant>\\n{answer}\\n</assistant>\"\n",
    "                            all_data.append({\"text\": formatted_text})\n",
    "                            \n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {excel_file}, sheet {sheet_name}: {e}\")\n",
    "    \n",
    "    print(f\"Total examples loaded: {len(all_data)}\")\n",
    "    \n",
    "    # 학습:검증 데이터 분리 (9:1)\n",
    "    train_size = int(len(all_data) * 0.9)\n",
    "    train_data = all_data[:train_size]\n",
    "    eval_data = all_data[train_size:]\n",
    "    \n",
    "    return Dataset.from_dict({\"text\": [item[\"text\"] for item in train_data]}), \\\n",
    "           Dataset.from_dict({\"text\": [item[\"text\"] for item in eval_data]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 토크나이저 준비 함수\n",
    "def prepare_model_and_tokenizer():\n",
    "    print(\"Loading model and tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=False, cache_dir=\"./\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float32,\n",
    "        device_map=None,\n",
    "        cache_dir=\"./\"\n",
    "    )\n",
    "    \n",
    "    # LoRA 설정 적용\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        target_modules=LORA_TARGET_MODULES,\n",
    "        bias=\"none\",\n",
    "        inference_mode=False,\n",
    "    )\n",
    "    \n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징 함수\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    result = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 콜백 클래스\n",
    "class LearningRateLoggerCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        optimizer = kwargs.get('optimizer', None)\n",
    "        if optimizer:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                current_lr = param_group['lr']\n",
    "                print(f\"Step {state.global_step}: Learning rate = {current_lr:.6f}\")\n",
    "        return control\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            print(f\"\\n===== Evaluation Results at Step {state.global_step} =====\")\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"{key}: {value:.4f}\")\n",
    "            print(\"=\" * 50)\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "train_dataset, eval_dataset = load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 및 토크나이저 준비\n",
    "model, tokenizer = prepare_model_and_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 토크나이징\n",
    "print(\"Tokenizing datasets...\")\n",
    "tokenized_train = train_dataset.map(\n",
    "    lambda x: tokenize_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "tokenized_eval = eval_dataset.map(\n",
    "    lambda x: tokenize_function(x, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 설정\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "os.makedirs(TB_LOG_DIR, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_dir=TB_LOG_DIR,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    ddp_find_unused_parameters=False,\n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "lr_callback = LearningRateLoggerCallback()\n",
    "tensorboard_callback = TensorBoardCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 초기화 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[lr_callback, tensorboard_callback],\n",
    ")\n",
    "\n",
    "print(\"\\n===== TensorBoard 실행 방법 =====\")\n",
    "print(f\"터미널에서 다음 명령어를 실행하세요:\")\n",
    "print(f\"tensorboard --logdir={TB_LOG_DIR}\")\n",
    "print(\"그런 다음 웹 브라우저에서 http://localhost:6006/ 으로 접속하세요.\\n\")\n",
    "\n",
    "# 초기 평가\n",
    "print(\"Initial evaluation...\")\n",
    "trainer.evaluate()\n",
    "\n",
    "# 학습 시작\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "print(\"Saving model...\")\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# 최종 평가\n",
    "print(\"Final evaluation...\")\n",
    "final_metrics = trainer.evaluate()\n",
    "print(\"\\n===== Final Evaluation Results =====\")\n",
    "for key, value in final_metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Training complete. Model saved to {OUTPUT_DIR}\")\n",
    "print(f\"TensorBoard 로그는 {TB_LOG_DIR}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
